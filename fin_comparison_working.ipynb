{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import imutils\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "#sys.path.append(os.path.dirname(__file__) + \"/../\")\n",
    "from scipy.misc import imread, imsave\n",
    "from skimage.measure import structural_similarity as ssim\n",
    "from config import load_config\n",
    "from dataset.factory import create as create_dataset\n",
    "from nnet import predict\n",
    "from util import visualize\n",
    "import cv2\n",
    "from dataset.pose_dataset import data_to_input\n",
    "\n",
    "\n",
    "from multiperson.detections import extract_detections\n",
    "from multiperson.predict import SpatialModel, eval_graph, get_person_conf_multicut\n",
    "from multiperson.visualize import PersonDraw, visualize_detections\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tkinter import messagebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vibrate():\n",
    "    pass\n",
    "def compare_images(slope1, slope2, allowance):\n",
    "    for key in slope1:\n",
    "        if abs(slope1[key]-slope2[key]) > allowance:\n",
    "            vibrate(key)\n",
    "            print(\"error at : \", key)\n",
    "            \n",
    "            \n",
    "def slope_calc(co1):\n",
    "    body_dict={'nose_right': co1[0],\n",
    "               'nose_left': co1[1],\n",
    "              'right_eye_ear': co1[2],\n",
    "              'left_eye_ear': co1[3],\n",
    "              'right_upper_arm':co1[4],\n",
    "              'left_upper_arm':co1[5],\n",
    "              'right_forearm': co1[6],\n",
    "              'left_forearm': co1[7],\n",
    "               'right_upper_leg':co1[8],\n",
    "               'left_upper_leg':co1[9],\n",
    "               'right_shin':co1[10],\n",
    "               'left_shin':co1[11]\n",
    "              }\n",
    "    body_dict['backbone']=[(int((body_dict['right_upper_arm'][0][0]+body_dict['left_upper_arm'][0][0])/2),\n",
    "                           int((body_dict['right_upper_arm'][0][1]+body_dict['left_upper_arm'][0][1])/2)),\n",
    "                           (int((body_dict['right_upper_leg'][0][0]+body_dict['left_upper_leg'][0][0])/2),\n",
    "                           int((body_dict['right_upper_leg'][0][1]+body_dict['left_upper_leg'][0][1])/2))]\n",
    "    for key in body_dict:\n",
    "        a=math.atan((body_dict['backbone'][1][1]-body_dict['backbone'][0][1])/(body_dict['backbone'][0][0]-body_dict['backbone'][1][0]))\n",
    "        slopes[key]=(math.atan((body_dict[key][1][1]-body_dict[key][0][1])/(body_dict[key][0][0]-body_dict[key][1][0])))-a\n",
    "    return slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_predict(frame):\n",
    "\n",
    "    # Load and setup CNN part detector\n",
    "    tf.reset_default_graph()\n",
    "    image= frame\n",
    "    image_batch = data_to_input(frame)\n",
    "    \n",
    "    # Compute prediction_n with the CNN\n",
    "    outputs_np = sess.run(outputs, feed_dict={inputs: image_batch})\n",
    "    scmap, locref, pairwise_diff = predict.extract_cnn_output(outputs_np, cfg, dataset.pairwise_stats)\n",
    "    detections = extract_detections(cfg, scmap, locref, pairwise_diff)\n",
    "    unLab, pos_array, unary_array, pwidx_array, pw_array = eval_graph(sm, detections)\n",
    "    m=time.time()\n",
    "    person_conf_multi = get_person_conf_multicut(sm, unLab, unary_array, pos_array)\n",
    "    img = np.copy(image)\n",
    "    #coor = PersonDraw.draw()\n",
    "    visim_multi = img.copy()\n",
    "    co1=draw_multi.draw(visim_multi, dataset, person_conf_multi, image)\n",
    "    return pos_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_people:  2\n",
      "#tracked objects: 0\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  3\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  3\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  5\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "cfg = load_config(\"demo/pose_cfg_multi.yaml\")\n",
    "dataset=create_dataset(cfg)\n",
    "sm = SpatialModel(cfg)\n",
    "sm.load()\n",
    "tf.reset_default_graph()\n",
    "draw_multi = PersonDraw()\n",
    "sess, inputs, outputs = predict.setup_pose_prediction(cfg)\n",
    "fps_time=0\n",
    "# Read image from file\n",
    "slopes={}\n",
    "dir=os.listdir(\"stick\")\n",
    "k=0\n",
    "cap=cv2.VideoCapture('exer.mp4')\n",
    "cap_user=cv2.VideoCapture(0)\n",
    "i=0\n",
    "while (True):\n",
    "    ret, orig_frame= cap.read()\n",
    "    ret2, orig_frame_user= cap_user.read()\n",
    "    if i%25 == 0:                   \n",
    "        \n",
    "        frame = cv2.resize(orig_frame, (0, 0), fx=0.50, fy=0.50)\n",
    "        #frame=orig_frame\n",
    "        user_frame=cv2.resize(orig_frame_user, (0, 0), fx=0.50, fy=0.50)\n",
    "        co1=run_predict(frame)\n",
    "        user_co1=run_predict(user_frame)\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            slope_reqd=slope_calc(co1)\n",
    "            slope_user=slope_calc(user_co1)\n",
    "            compare_images(slope_reqd, slope_user)\n",
    "        except IndexError:\n",
    "            #if len(co1)!=len(user_co1):\n",
    "            pass\n",
    "            \n",
    "        cv2.putText(user_frame,\n",
    "                    \"FPS: %f\" % (1.0 / (time.time() - fps_time)),\n",
    "                    (10, 10),  cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                    (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.imshow('user_frame', user_frame)\n",
    "        cv2.imshow('frame', frame)\n",
    "        fps_time=time.time()\n",
    "        #visualize.waitforbuttonpress()\n",
    "        if cv2.waitKey(10)==ord('q'):\n",
    "            break\n",
    "elapsed= time.time()-start_time\n",
    "#print(\"sse score : \", sse)\n",
    "cap.release()\n",
    "cap_user.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pwidx_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4d6d2cf794a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpwidx_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pwidx_array' is not defined"
     ]
    }
   ],
   "source": [
    "pwidx_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cap_user.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_people:  5\n",
      "#tracked objects: 1\n"
     ]
    }
   ],
   "source": [
    "image= frame\n",
    "image_batch = data_to_input(frame)\n",
    "\n",
    "# Compute prediction_n with the CNN\n",
    "outputs_np = sess.run(outputs, feed_dict={inputs: image_batch})\n",
    "scmap, locref, pairwise_diff = predict.extract_cnn_output(outputs_np, cfg, dataset.pairwise_stats)\n",
    "detections = extract_detections(cfg, scmap, locref, pairwise_diff)\n",
    "unLab, pos_array, unary_array, pwidx_array, pw_array = eval_graph(sm, detections)\n",
    "m=time.time()\n",
    "person_conf_multi = get_person_conf_multicut(sm, unLab, unary_array, pos_array)\n",
    "img = np.copy(image)\n",
    "#coor = PersonDraw.draw()\n",
    "visim_multi = img.copy()\n",
    "co1=draw_multi.draw2(visim_multi, dataset, person_conf_multi, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_array1=pos_array.round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[300,  87],\n",
       "       [306,  83],\n",
       "       [300,  84],\n",
       "       [320,  86],\n",
       "       [337, 108],\n",
       "       [301, 102],\n",
       "       [364,  69],\n",
       "       [355, 132],\n",
       "       [291,  76],\n",
       "       [354,  21],\n",
       "       [295,  38],\n",
       "       [353, 130],\n",
       "       [295,  40],\n",
       "       [354,  21],\n",
       "       [335, 202],\n",
       "       [305, 204],\n",
       "       [349, 267],\n",
       "       [288, 251],\n",
       "       [396, 322],\n",
       "       [290, 293]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_array1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[299.80378212,  86.60445786],\n",
       "       [305.66500473,  83.29327565],\n",
       "       [299.62593976,  84.40048602],\n",
       "       [320.23118019,  86.29758811],\n",
       "       [336.91520309, 107.66185451],\n",
       "       [300.94690591, 101.98846591],\n",
       "       [364.30259404,  69.32882512],\n",
       "       [354.9719398 , 131.80669855],\n",
       "       [290.6085434 ,  75.84775499],\n",
       "       [354.22004008,  20.73260653],\n",
       "       [295.01453686,  38.40702653],\n",
       "       [352.56647182, 130.39948952],\n",
       "       [294.56543016,  39.7606442 ],\n",
       "       [354.24010086,  21.42583728],\n",
       "       [335.01036382, 201.75517106],\n",
       "       [305.25822306, 203.57265311],\n",
       "       [348.92772913, 266.89176798],\n",
       "       [287.72134924, 250.79992747],\n",
       "       [395.92394735, 322.20143902],\n",
       "       [290.40567827, 292.94609219]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
