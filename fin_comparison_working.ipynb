{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import imutils\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "#sys.path.append(os.path.dirname(__file__) + \"/../\")\n",
    "from scipy.misc import imread, imsave\n",
    "from skimage.measure import structural_similarity as ssim\n",
    "from config import load_config\n",
    "from dataset.factory import create as create_dataset\n",
    "from nnet import predict\n",
    "from util import visualize\n",
    "import cv2\n",
    "from dataset.pose_dataset import data_to_input\n",
    "\n",
    "\n",
    "from multiperson.detections import extract_detections\n",
    "from multiperson.predict import SpatialModel, eval_graph, get_person_conf_multicut\n",
    "from multiperson.visualize import PersonDraw, visualize_detections\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tkinter import messagebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vibrate(key):\n",
    "    os.system('play  --null --channels 1 synth %s sine %f' % (1, 500))\n",
    "    \n",
    "    \n",
    "    \n",
    "def compare_images(slope1, slope2, allowance):\n",
    "    for key in slope1:\n",
    "        print(key,slope1[key]-slope2[key])\n",
    "        if abs(slope1[key]-slope2[key]) > allowance:\n",
    "            vibrate(key)\n",
    "            print(\"error at : \", key)\n",
    "            return (key,slope1[key]-slope2[key])\n",
    "            \n",
    "def slope_calc(co1, co2):\n",
    "    body_dict={'right_upper_arm':co1[4],\n",
    "              'left_upper_arm':co1[5],\n",
    "               'right_upper_leg':co1[8],\n",
    "               'left_upper_leg':co1[9]\n",
    "              }\n",
    "    slopes={}\n",
    "    slopes_user={}\n",
    "    body_dict['backbone_top']=np.array([int((body_dict['right_upper_arm'][0]+body_dict['left_upper_arm'][0])/2),\n",
    "                           int((body_dict['right_upper_arm'][1]+body_dict['left_upper_arm'][1])/2)])\n",
    "    body_dict['backbone_bottom']=np.array([int((body_dict['right_upper_leg'][0]+body_dict['left_upper_leg'][0])/2),\n",
    "                           int((body_dict['right_upper_leg'][1]+body_dict['left_upper_leg'][1])/2)])\n",
    "\n",
    "    body_dict_lines={\n",
    "        'backbone':(body_dict['backbone_top'], body_dict['backbone_bottom']),\n",
    "        'nose_right':(co1[0],co1[1]),\n",
    "        'nose_left': (co1[0], co1[2]),\n",
    "        'right_eye_ear': (co1[1], co1[3]),\n",
    "        'left_eye_ear':(co1[2],co1[4]),\n",
    "        'right_upper_arm':(co1[5],co1[7]),\n",
    "        'left_upper_arm':(co1[6],co1[8]),\n",
    "        'right_forearm': (co1[7],co1[9]),\n",
    "        'left_forearm': (co1[8],co1[10]),\n",
    "        'right_upper_leg':(co1[11],co1[13]),\n",
    "        'left_upper_leg':(co1[12],co1[14]),\n",
    "        'right_shin':(co1[13],co1[15]),\n",
    "        'left_shin':(co1[14],co1[16])\n",
    "    }\n",
    "\n",
    "\n",
    "    for key in body_dict_lines:\n",
    "        a=math.atan((body_dict_lines['backbone'][1][1]-body_dict_lines['backbone'][0][1])/(body_dict_lines['backbone'][0][0]-body_dict_lines['backbone'][1][0]))\n",
    "        slopes[key]=(math.atan((body_dict_lines[key][1][1]-body_dict_lines[key][0][1])/(body_dict_lines[key][0][0]-body_dict_lines[key][1][0])))-a\n",
    "    \n",
    "    \n",
    "    body_dict_user={'right_upper_arm':co2[4],\n",
    "              'left_upper_arm':co2[5],\n",
    "               'right_upper_leg':co2[8],\n",
    "               'left_upper_leg':co2[9]\n",
    "              }\n",
    "    body_dict_user['backbone_top']=np.array([int((body_dict_user['right_upper_arm'][0]+body_dict_user['left_upper_arm'][0])/2),\n",
    "                           int((body_dict_user['right_upper_arm'][1]+body_dict_user['left_upper_arm'][1])/2)])\n",
    "    body_dict_user['backbone_bottom']=np.array([int((body_dict_user['right_upper_leg'][0]+body_dict_user['left_upper_leg'][0])/2),\n",
    "                           int((body_dict_user['right_upper_leg'][1]+body_dict_user['left_upper_leg'][1])/2)])\n",
    "\n",
    "    body_dict_lines_user={\n",
    "        'backbone':(body_dict_user['backbone_top'], body_dict_user['backbone_bottom']),\n",
    "        'nose_right':(co2[0],co2[1]),\n",
    "        'nose_left': (co2[0], co2[2]),\n",
    "        'right_eye_ear': (co2[1], co2[3]),\n",
    "        'left_eye_ear':(co2[2],co2[4]),\n",
    "        'right_upper_arm':(co2[5],co2[7]),\n",
    "        'left_upper_arm':(co2[6],co2[8]),\n",
    "        'right_forearm': (co2[7],co2[9]),\n",
    "        'left_forearm': (co2[8],co2[10]),\n",
    "        'right_upper_leg':(co2[11],co2[13]),\n",
    "        'left_upper_leg':(co2[12],co2[14]),\n",
    "        'right_shin':(co2[13],co2[15]),\n",
    "        'left_shin':(co2[14],co2[16])\n",
    "    }\n",
    "\n",
    "\n",
    "    for key in body_dict_lines_user:\n",
    "        b=math.atan((body_dict_lines_user['backbone'][1][1]-body_dict_lines_user['backbone'][0][1])/(body_dict_lines_user['backbone'][0][0]-body_dict_lines_user['backbone'][1][0]))\n",
    "        slopes_user[key]=(math.atan((body_dict_lines_user[key][1][1]-body_dict_lines_user[key][0][1])/(body_dict_lines_user[key][0][0]-body_dict_lines_user[key][1][0])))-a\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return slopes, slopes_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone 0.39833239483010896\n",
      "nose_right 0.03123983343026837\n",
      "nose_left 0.2110933332227467\n",
      "right_eye_ear -0.08314123188844125\n",
      "left_eye_ear 0.16037544397595072\n",
      "right_upper_arm 0.4248321629193428\n",
      "left_upper_arm 1.3664596475079354\n",
      "error at :  left_upper_arm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('left_upper_arm', 1.3664596475079354)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b=slope_calc(co1, user_co1)\n",
    "compare_images(a,b,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'backbone': 0.0,\n",
       " 'left_eye_ear': -0.7202164805356259,\n",
       " 'left_forearm': -2.4048048144742307,\n",
       " 'left_shin': 0.43780767561273026,\n",
       " 'left_upper_arm': -1.3870399318299746,\n",
       " 'left_upper_leg': 0.44533104463769546,\n",
       " 'nose_left': -2.1861358686002887,\n",
       " 'nose_right': -0.43548604201291374,\n",
       " 'right_eye_ear': -1.4007377052028402,\n",
       " 'right_forearm': 0.1859303045838463,\n",
       " 'right_shin': -2.6212198197623344,\n",
       " 'right_upper_arm': -2.431114531727153,\n",
       " 'right_upper_leg': -2.6010416262911633}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slope_calc(user_co1, co1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'backbone': 0.0,\n",
       " 'left_eye_ear': -0.9581734313897842,\n",
       " 'left_forearm': -2.840619645996001,\n",
       " 'left_shin': -3.0163804989027456,\n",
       " 'left_upper_arm': -0.41891267915214825,\n",
       " 'left_upper_leg': -2.967644861165743,\n",
       " 'nose_left': -2.373374930207651,\n",
       " 'nose_right': -0.8025786034127543,\n",
       " 'right_eye_ear': -1.8822113319213905,\n",
       " 'right_forearm': 0.040893719547647756,\n",
       " 'right_shin': -3.0168760390009357,\n",
       " 'right_upper_arm': -2.404614763637919,\n",
       " 'right_upper_leg': 0.027996756235124654}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_predict(frame):\n",
    "\n",
    "    # Load and setup CNN part detector\n",
    "    #tf.reset_default_graph()\n",
    "    image= frame\n",
    "    image_batch = data_to_input(frame)\n",
    "    \n",
    "    # Compute prediction_n with the CNN\n",
    "    outputs_np = sess.run(outputs, feed_dict={inputs: image_batch})\n",
    "    scmap, locref, pairwise_diff = predict.extract_cnn_output(outputs_np, cfg, dataset.pairwise_stats)\n",
    "    detections = extract_detections(cfg, scmap, locref, pairwise_diff)\n",
    "    unLab, pos_array, unary_array, pwidx_array, pw_array = eval_graph(sm, detections)\n",
    "    m=time.time()\n",
    "    person_conf_multi = get_person_conf_multicut(sm, unLab, unary_array, pos_array)\n",
    "    img = np.copy(image)\n",
    "    #coor = PersonDraw.draw()\n",
    "    visim_multi = img.copy()\n",
    "    co1=draw_multi.draw(visim_multi, dataset, person_conf_multi, image)\n",
    "    return pos_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## start_time=time.time()\n",
    "cfg = load_config(\"demo/pose_cfg_multi.yaml\")\n",
    "dataset=create_dataset(cfg)\n",
    "sm = SpatialModel(cfg)\n",
    "sm.load()\n",
    "tf.reset_default_graph()\n",
    "draw_multi = PersonDraw()\n",
    "sess, inputs, outputs = predict.setup_pose_prediction(cfg)\n",
    "fps_time=0\n",
    "# Read image from file\n",
    "slopes={}\n",
    "k=0\n",
    "cap=cv2.VideoCapture('msgifs/icon4.gif')\n",
    "cap_user=cv2.VideoCapture('user.mp4')\n",
    "i=0\n",
    "while (True):\n",
    "    ret, orig_frame= cap.read()\n",
    "    ret2, orig_frame_user= cap_user.read()\n",
    "    if i%25 == 0:                   \n",
    "        \n",
    "        frame = cv2.resize(orig_frame, (0, 0), fx=0.50, fy=0.50)\n",
    "        #frame=orig_frame\n",
    "        user_frame=cv2.resize(orig_frame_user, (0, 0), fx=0.50, fy=0.50)\n",
    "        co1=run_predict(frame)\n",
    "        user_co1=run_predict(frame)\n",
    "        try:\n",
    "            slope_reqd, slope_user=slope_calc(co1, user_co1)\n",
    "            compare_images(slope_reqd, slope_user, 0.75)\n",
    "        except IndexError:\n",
    "            #if len(co1)!=len(user_co1):\n",
    "            pass\n",
    "            \n",
    "        cv2.putText(user_frame,\n",
    "                    \"FPS: %f\" % (1.0 / (time.time() - fps_time)),\n",
    "                    (10, 10),  cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                    (0, 255, 0), 2)\n",
    "        cv2.imshow('user_frame', user_frame)\n",
    "        cv2.imshow('frame', frame)\n",
    "        fps_time=time.time()\n",
    "        #visualize.waitforbuttonpress()\n",
    "        if cv2.waitKey(10)==ord('q'):\n",
    "            break\n",
    "elapsed= time.time()-start_time\n",
    "cap.release()\n",
    "cap_user.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cap_user.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST ON IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_people:  1\n",
      "#tracked objects: 0\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "cfg = load_config(\"demo/pose_cfg_multi.yaml\")\n",
    "dataset=create_dataset(cfg)\n",
    "sm = SpatialModel(cfg)\n",
    "sm.load()\n",
    "tf.reset_default_graph()\n",
    "draw_multi = PersonDraw()\n",
    "sess, inputs, outputs = predict.setup_pose_prediction(cfg)\n",
    "fps_time=0\n",
    "# Read image from file\n",
    "slopes={}\n",
    "k=0\n",
    "cap=cv2.VideoCapture('exer.mp4')\n",
    "cap_user=cv2.VideoCapture(0)\n",
    "i=0\n",
    "\"\"\"\n",
    "ret, orig_frame=cap.read()\n",
    "ret2, orig_frame_user=cap.read()\n",
    "\"\"\"\n",
    "orig_frame = cv2.imread('sample.jpg')\n",
    "orig_frame_user = cv2.imread('raised.jpg')\n",
    "frame = cv2.resize(orig_frame, (0, 0), fx=0.50, fy=0.50)\n",
    "user_frame=cv2.resize(orig_frame_user, (0, 0), fx=0.50, fy=0.50)\n",
    "co1=run_predict(frame).astype(int)\n",
    "user_co1=run_predict(user_frame).astype(int)\n",
    "\n",
    "\n",
    "try:\n",
    "    slope_reqd=slope_calc(co1)\n",
    "    slope_user=slope_calc(user_co1)\n",
    "    compare_images(slope_reqd, slope_user,1)\n",
    "except IndexError:\n",
    "    #if len(co1)!=len(user_co1):\n",
    "    print(\"Index Error\")\n",
    "    pass\n",
    "\n",
    "cv2.putText(user_frame,\n",
    "            \"FPS: %f, error : \" % (1.0 / (time.time() - fps_time)),\n",
    "            (10, 10),  cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "            (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow('user_frame', user_frame)\n",
    "cv2.imshow('frame', frame)\n",
    "fps_time=time.time()\n",
    "#visualize.waitforbuttonpress()\n",
    "if cv2.waitKey(0)==ord('q'):\n",
    "    cap.release()\n",
    "    cap_user.release()\n",
    "    cv2.destroyAllWindows()\n",
    "elapsed= time.time()-start_time\n",
    "#print(\"sse score : \", sse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cap_user.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_people:  1\n",
      "#tracked objects: 1\n"
     ]
    }
   ],
   "source": [
    "frame=cv2.imread('sample.jpg')\n",
    "co=run_predict(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'backbone': 0.0,\n",
       " 'left_eye_ear': -0.7202164805356259,\n",
       " 'left_forearm': -2.4048048144742307,\n",
       " 'left_shin': 0.43780767561273026,\n",
       " 'left_upper_arm': -1.3870399318299746,\n",
       " 'left_upper_leg': 0.44533104463769546,\n",
       " 'nose_left': -2.1861358686002887,\n",
       " 'nose_right': -0.43548604201291374,\n",
       " 'right_eye_ear': -1.4007377052028402,\n",
       " 'right_forearm': 0.1859303045838463,\n",
       " 'right_shin': -2.6212198197623344,\n",
       " 'right_upper_arm': -2.431114531727153,\n",
       " 'right_upper_leg': -2.6010416262911633}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_dict_lines={\n",
    "    'backbone':(body_dict['backbone_top'], body_dict['backbone_bottom']),\n",
    "    'nose_right':(co1[0],co1[1]),\n",
    "    'nose_left': (co1[0], co1[2]),\n",
    "    'right_eye_ear': (co1[1], co1[3]),\n",
    "    'left_eye_ear':(co1[2],co1[4]),\n",
    "    'right_upper_arm':(co1[5],co1[7]),\n",
    "    'left_upper_arm':(co1[6],co1[8]),\n",
    "    'right_forearm': (co1[7],co1[9]),\n",
    "    'left_forearm': (co1[8],co1[10]),\n",
    "    'right_upper_leg':(co1[11],co1[13]),\n",
    "    'left_upper_leg':(co1[12],co1[14]),\n",
    "    'right_shin':(co1[13],co1[15]),\n",
    "    'left_shin':(co1[14],co1[16])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(co1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135, 42)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(body_dict_lines['backbone'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
