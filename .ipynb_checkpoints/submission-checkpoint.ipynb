{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import imutils\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.misc import imread, imsave\n",
    "from skimage.measure import structural_similarity as ssim\n",
    "from config import load_config\n",
    "from dataset.factory import create as create_dataset\n",
    "from nnet import predict\n",
    "from util import visualize\n",
    "import cv2\n",
    "from dataset.pose_dataset import data_to_input\n",
    "\n",
    "from multiperson.detections import extract_detections\n",
    "from multiperson.predict import SpatialModel, eval_graph, get_person_conf_multicut\n",
    "from multiperson.visualize import PersonDraw, visualize_detections\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_predict(frame, sess, inputs, outputs, cfg, dataset, sm, draw_multi):\n",
    "    tf.reset_default_graph()\n",
    "    image= frame\n",
    "    image_batch = data_to_input(frame)\n",
    "    \n",
    "    # Compute prediction_n with the CNN\n",
    "    outputs_np = sess.run(outputs, feed_dict={inputs: image_batch})\n",
    "    scmap, locref, pairwise_diff = predict.extract_cnn_output(outputs_np, cfg, dataset.pairwise_stats)\n",
    "    detections = extract_detections(cfg, scmap, locref, pairwise_diff)\n",
    "    unLab, pos_array, unary_array, pwidx_array, pw_array = eval_graph(sm, detections)\n",
    "    m=time.time()\n",
    "    person_conf_multi = get_person_conf_multicut(sm, unLab, unary_array, pos_array)\n",
    "    img = np.copy(image)\n",
    "    visim_multi = img.copy()\n",
    "    draw_multi.draw(visim_multi, dataset, person_conf_multi, image)\n",
    "    return pos_array.round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n"
     ]
    }
   ],
   "source": [
    "cfg = load_config(\"demo/pose_cfg_multi.yaml\")\n",
    "dataset=create_dataset(cfg)\n",
    "sm = SpatialModel(cfg)\n",
    "sm.load()\n",
    "tf.reset_default_graph()\n",
    "draw_multi = PersonDraw()\n",
    "sess, inputs, outputs = predict.setup_pose_prediction(cfg)\n",
    "fps_time=0\n",
    "i=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "sitting straight, with a hunched back, reclined, arm crossed, or in a kneeling posture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_posture(body_dict):\n",
    "    if body_dict['hand_right'][0]<body_dict['backbone_top'][0] and body_dict['hand_left'][0]>body_dict['backbone_top'][0]:\n",
    "        printf(\"ARM CROSSED\")\n",
    "    if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'body_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-63d918c32d6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbody_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'body_dict' is not defined"
     ]
    }
   ],
   "source": [
    "body_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_people:  2\n",
      "#tracked objects: 1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 16 is out of bounds for axis 0 with size 16",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0c73c6ee45d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;34m'knee_left'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mco1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;34m'foot_right'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mco1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;34m'foot_left'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mco1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m           }\n\u001b[1;32m     28\u001b[0m         \"\"\"\n",
      "\u001b[0;31mIndexError\u001b[0m: index 16 is out of bounds for axis 0 with size 16"
     ]
    }
   ],
   "source": [
    "cap=cv2.VideoCapture('exer.mp4')\n",
    "\n",
    "while (True):\n",
    "    ret, frame= cap.read()\n",
    "    if i%25 == 0:                   \n",
    "        frame = cv2.resize(frame, (0, 0), fx=0.50, fy=0.50)\n",
    "        co1=run_predict(frame, sess, inputs, outputs, cfg, dataset, sm, draw_multi)\n",
    "\n",
    "\n",
    "        body_dict={'nose': co1[0],\n",
    "           'eye_right': co1[1],\n",
    "          'eye_left': co1[2],\n",
    "          'ear_right': co1[3],\n",
    "          'ear_left':co1[4],\n",
    "          'shoulder_right':co1[5],\n",
    "          'shoulder_left': co1[6],\n",
    "          'elbow_right': co1[7],\n",
    "           'elbow_left':co1[8],\n",
    "           'hand_right':co1[9],\n",
    "           'hand_left':co1[10],\n",
    "           'thigh_right':co1[11],\n",
    "            'thigh_left':co1[12],\n",
    "            'knee_right':co1[13],\n",
    "            'knee_left':co1[14],\n",
    "            'foot_right':co1[15],\n",
    "            'foot_left':co1[16],\n",
    "          }\n",
    "        \"\"\"\n",
    "        body_dict['backbone']=[(int((body_dict['right_upper_arm'][0][0]+body_dict['left_upper_arm'][0][0])/2),\n",
    "                       int((body_dict['right_upper_arm'][0][1]+body_dict['left_upper_arm'][0][1])/2)),\n",
    "                       (int((body_dict['right_upper_leg'][0][0]+body_dict['left_upper_leg'][0][0])/2),\n",
    "                       int((body_dict['right_upper_leg'][0][1]+body_dict['left_upper_leg'][0][1])/2))]\n",
    "        \"\"\"\n",
    "\n",
    "        cv2.putText(frame,\n",
    "                    \"FPS: %f\" % (1.0 / (time.time() - fps_time)),\n",
    "                    (10, 10),  cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                    (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "        cv2.imshow('frame', frame)\n",
    "        fps_time=time.time()\n",
    "        #visualize.waitforbuttonpress()\n",
    "        if cv2.waitKey(10)==ord('q'):\n",
    "            break\n",
    "\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([248,  56])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_dict['eye_left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_people:  1\n",
      "#tracked objects: 1\n"
     ]
    }
   ],
   "source": [
    "frame=cv2.imread('sample.jpg')\n",
    "co1=run_predict(frame, sess, inputs, outputs, cfg, dataset, sm, draw_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('frame', frame)\n",
    "if cv2.waitKey(0)==ord('q'):\n",
    "    #cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2=np.zeros((606,671,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3=np.zeros((606,671,3))\n",
    "\n",
    "cv2.line(frame2,body_dict['backbone_bottom'], body_dict['backbone_bottom'], (0,255,0),1)\n",
    "cv2.line(frame2,tuple(co1[0]),tuple(co1[1]),(0,255,0),1)\n",
    "cv2.line(frame2,tuple(co1[0]),tuple(co1[2]),(0,255,0),1)\n",
    "cv2.line(frame2,tuple(co1[1]),tuple(co1[3]),(0,255,0),1)\n",
    "cv2.line(frame2,tuple(co1[2]),tuple(co1[4]),(0,255,0),1)\n",
    "cv2.line(frame2,tuple(co1[5]),tuple(co1[7]),(0,255,0),1)\n",
    "cv2.line(frame2,tuple(co1[6]),tuple(co1[8]),(0,255,0),1)\n",
    "\n",
    "cv2.line(frame2,tuple(co1[7]),tuple(co1[9]),(0,255,0),1)\n",
    "cv2.line(frame2,tuple(co1[8]),tuple(co1[10]),(0,255,0),1)\n",
    "\n",
    "cv2.line(frame2,tuple(co1[11]),tuple(co1[13]),(0,255,0),1)\n",
    "cv2.line(frame2,tuple(co1[12]),tuple(co1[14]),(0,255,0),1)\n",
    "\n",
    "cv2.line(frame2,tuple(co1[13]),tuple(co1[15]),(0,255,0),1)\n",
    "cv2.line(frame2,tuple(co1[14]),tuple(co1[16]),(0,255,0),1)\n",
    "cv2.line(frame3,body_dict['backbone_bottom'], body_dict['backbone_bottom'], (0,255,0),1)\n",
    "\n",
    "#cv2.line(frame2,tuple(body_dict['right_eye_ear']),tuple(body_dict['nose_right']), (0,255,0))\n",
    "\n",
    "cv2.imshow('frame', frame3)\n",
    "if cv2.waitKey(0)==ord('q'):\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([245, 393])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co1[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(268, 268) (259, 119)\n"
     ]
    }
   ],
   "source": [
    "print(body_dict['backbone_bottom'], body_dict['backbone_top'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_dict['backbone_top']=((int((body_dict['shoulder_right'][0]+int(body_dict['shoulder_left'][0]))/2),\n",
    "                       int((body_dict['shoulder_right'][1]+int(body_dict['shoulder_left'][1]))/2)))\n",
    "body_dict['backbone_bottom']=((int((body_dict['thigh_left'][0]+int(body_dict['thigh_right'][0]))/2),\n",
    "                       int((body_dict['thigh_left'][1]+int(body_dict['thigh_right'][1]))/2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
