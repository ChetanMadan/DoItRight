{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "#sys.path.append(os.path.dirname(__file__) + \"/../\")\n",
    "from scipy.misc import imread, imsave\n",
    "from skimage.measure import structural_similarity as ssim\n",
    "from config import load_config\n",
    "from dataset.factory import create as create_dataset\n",
    "from nnet import predict\n",
    "from util import visualize\n",
    "import cv2\n",
    "from dataset.pose_dataset import data_to_input\n",
    "\n",
    "\n",
    "from multiperson.detections import extract_detections\n",
    "from multiperson.predict import SpatialModel, eval_graph, get_person_conf_multicut\n",
    "from multiperson.visualize import PersonDraw, visualize_detections\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "def mse(imageA,imageB):\n",
    "    err = np.sum((imageA.astype(\"float\")-imageB.astype(\"float\"))**2)\n",
    "    err /= float(imageA.shape[0]*imageA.shape[1])\n",
    "    return err\n",
    "\n",
    "def compare_images(imageA, imageB, title):\n",
    "    m = mse(imageA, imageB)\n",
    "    s = ssim(imageA, imageB)\n",
    "    fig = plt.figure(title)\n",
    "    plt.suptitle(\"MSE: %.2f, SSIM: %.2f\" % (m, s))\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    plt.imshow(imageA, cmap = plt.cm.gray)\n",
    "    plt.axis(\"off\")\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    \n",
    "    plt.imshow(imageB, cmap = plt.cm.gray)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    return(s,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_people:  1\n",
      "#tracked objects: 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b0657a304a33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mmse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sse score : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean squared error : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "cfg = load_config(\"demo/pose_cfg_multi.yaml\")\n",
    "dataset = create_dataset(cfg)\n",
    "sm = SpatialModel(cfg)\n",
    "sm.load()\n",
    "draw_multi = PersonDraw()\n",
    "# Load and setup CNN part detector\n",
    "sess, inputs, outputs = predict.setup_pose_prediction(cfg)\n",
    "\n",
    "# Read image from file\n",
    "dir=os.listdir(\"stick\")\n",
    "k=0\n",
    "cap=cv2.VideoCapture(0)\n",
    "i=0\n",
    "while True:\n",
    "        if i%20 == 0:                   \n",
    "                ret, orig_frame= cap.read()\n",
    "                frame = cv2.resize(orig_frame, (0, 0), fx=0.30, fy=0.30)\n",
    "                image= frame\n",
    "                sse=0\n",
    "                mse=0\n",
    "                \n",
    "                image_batch = data_to_input(frame)\n",
    "\n",
    "                # Compute prediction with the CNN\n",
    "                outputs_np = sess.run(outputs, feed_dict={inputs: image_batch})\n",
    "\n",
    "                scmap, locref, pairwise_diff = predict.extract_cnn_output(outputs_np, cfg, dataset.pairwise_stats)\n",
    "\n",
    "                detections = extract_detections(cfg, scmap, locref, pairwise_diff)\n",
    "\n",
    "                unLab, pos_array, unary_array, pwidx_array, pw_array = eval_graph(sm, detections)\n",
    "\n",
    "                person_conf_multi = get_person_conf_multicut(sm, unLab, unary_array, pos_array)\n",
    "                img = np.copy(image)\n",
    "                #coor = PersonDraw.draw()\n",
    "                visim_multi = img.copy()\n",
    "                co1=draw_multi.draw(visim_multi, dataset, person_conf_multi)\n",
    "                plt.imshow(visim_multi)\n",
    "                cv2.destroyAllWindows()\n",
    "                #plt.show()\n",
    "                visualize.waitforbuttonpress()\n",
    "                #print(\"this is draw : \", co1)\n",
    "                if k==1:\n",
    "                    qwr = np.zeros((1920,1080,3), np.uint8)\n",
    "\n",
    "                    cv2.line(qwr, co1[5][0], co1[5][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[7][0], co1[7][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[6][0], co1[6][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[4][0], co1[4][1],(255,0,0),3)\n",
    "\n",
    "                    cv2.line(qwr, co1[9][0], co1[9][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[11][0], co1[11][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[8][0], co1[8][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[10][0], co1[10][1],(255,0,0),3)\n",
    "                    # In[9]:\n",
    "                    cv2.imshow('r',qwr)\n",
    "                    qwr2=\"stick/frame\"+str(k)+\".jpg\"\n",
    "                    qw1 = cv2.cvtColor(qwr, cv2.COLOR_BGR2GRAY)\n",
    "                    qw2= cv2.cvtColor(qwr2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    fig = plt.figure(\"Images\")\n",
    "                    images = (\"Original\", qw1), (\"Contrast\", qw2)\n",
    "                    for (i, (name, image)) in enumerate(images):\n",
    "                            ax = fig.add_subplot(1, 3, i + 1)\n",
    "                            ax.set_title(name)\n",
    "                    plt.imshow(hash(tuple(image)))\n",
    "                    # compare the images\n",
    "                    s,m=compare_images(qw1, qw2, \"Image1 vs Image2\")\n",
    "                    k+=1\n",
    "                    sse=s\n",
    "                    mse=m\n",
    "                if cv2.waitKey(0):\n",
    "                    print(\"sse score : \", sse)\n",
    "                    print(\"Mean squared error : \", mse)\n",
    "                    break\n",
    "                \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture('demo/seed.mp4')\n",
    "i=0\n",
    "j=0\n",
    "cap1=cv2.VideoCapture('demo/comp.mp4')\n",
    "while True:\n",
    "    ret, orig_frame= cap.read()\n",
    "    if i%2 == 0:\n",
    "                ret, orig_frame= cap.read()\n",
    "                ret2, frame2 = cap1.read()\n",
    "                frame = cv2.resize(orig_frame, (0, 0), fx=0.35, fy=0.35)\n",
    "                frame2 = cv2.resize(orig_frame, (0, 0), fx=0.35, fy=0.35)\n",
    "                image= frame\n",
    "                cv2.imwrite('written/img%d.jpg'%j, frame)\n",
    "                j=j+1\n",
    "                image2=frame2\n",
    "                if cv2.waitKey(0):\n",
    "                    break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program To Read video \n",
    "# and Extract Frames \n",
    "import cv2 \n",
    "\n",
    "# Function to extract frames \n",
    "def FrameCapture(path): \n",
    "\t\n",
    "\t# Path to video file \n",
    "    vidObj = cv2.VideoCapture(path) \n",
    "\n",
    "\t# Used as counter variable \n",
    "    count = 0\n",
    "    i=0\n",
    "\n",
    "\t# checks whether frames were extracted \n",
    "    success = 1\n",
    "    while success: \n",
    "        if i%30==0:\n",
    "            # vidObj object calls read \n",
    "            # function extract frames \n",
    "            success, image = vidObj.read() \n",
    "\n",
    "            # Saves the frames with frame-count \n",
    "            cv2.imwrite(\"written/frame%d.jpg\" % count, image) \n",
    "\n",
    "            count += 1\n",
    "\n",
    "# Driver Code \n",
    "\t# Calling the function \n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "FrameCapture('demo/seed.mp4') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-a21be215cc0b>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-a21be215cc0b>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    for i in range ()\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#loop for creating stick figures for multiple images :-\n",
    "for i in range ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = os.listdir(\"written\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ded5ba42480f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
