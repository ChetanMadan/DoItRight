{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "#sys.path.append(os.path.dirname(__file__) + \"/../\")\n",
    "from scipy.misc import imread, imsave\n",
    "from skimage.measure import structural_similarity as ssim\n",
    "from config import load_config\n",
    "from dataset.factory import create as create_dataset\n",
    "from nnet import predict\n",
    "from util import visualize\n",
    "import cv2\n",
    "from dataset.pose_dataset import data_to_input\n",
    "\n",
    "\n",
    "from multiperson.detections import extract_detections\n",
    "from multiperson.predict import SpatialModel, eval_graph, get_person_conf_multicut\n",
    "from multiperson.visualize import PersonDraw, visualize_detections\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "def mse(imageA,imageB):\n",
    "    err = np.sum((imageA.astype(\"float\")-imageB.astype(\"float\"))**2)\n",
    "    err /= float(imageA.shape[0]*imageA.shape[1])\n",
    "    return err\n",
    "\n",
    "def compare_images(imageA, imageB, title):\n",
    "    m = mse(imageA, imageB)\n",
    "    s = ssim(imageA, imageB)\n",
    "    fig = plt.figure(title)\n",
    "    plt.suptitle(\"MSE: %.2f, SSIM: %.2f\" % (m, s))\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    plt.imshow(imageA, cmap = plt.cm.gray)\n",
    "    plt.axis(\"off\")\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    \n",
    "    plt.imshow(imageB, cmap = plt.cm.gray)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    return(s,m)\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "start_time=time.time()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.reset_default_graph()\n",
    "cfg = load_config(\"demo/pose_cfg_multi.yaml\")\n",
    "dataset = create_dataset(cfg)\n",
    "sm = SpatialModel(cfg)\n",
    "sm.load()\n",
    "draw_multi = PersonDraw()\n",
    "# Load and setup CNN part detector\n",
    "sess, inputs, outputs = predict.setup_pose_prediction(cfg)\n",
    "\n",
    "# Read image from file\n",
    "dir=os.listdir(\"stick\")\n",
    "k=0\n",
    "cap=cv2.VideoCapture(0)\n",
    "i=0\n",
    "while (cap.isOpened()):\n",
    "            i+=1                  \n",
    "            ret, orig_frame= cap.read()\n",
    "            if ret==True:\n",
    "                frame = cv2.resize(orig_frame, (0, 0), fx=0.30, fy=0.30)\n",
    "                image= frame\n",
    "                sse=0\n",
    "                mse=0\n",
    "                image_batch = data_to_input(frame)\n",
    "\n",
    "                # Compute prediction with the CNN\n",
    "                outputs_np = sess.run(outputs, feed_dict={inputs: image_batch})\n",
    "\n",
    "                scmap, locref, pairwise_diff = predict.extract_cnn_output(outputs_np, cfg, dataset.pairwise_stats)\n",
    "\n",
    "                detections = extract_detections(cfg, scmap, locref, pairwise_diff)\n",
    "\n",
    "                unLab, pos_array, unary_array, pwidx_array, pw_array = eval_graph(sm, detections)\n",
    "\n",
    "                person_conf_multi = get_person_conf_multicut(sm, unLab, unary_array, pos_array)\n",
    "                img = np.copy(image)\n",
    "                #coor = PersonDraw.draw()\n",
    "                visim_multi = img.copy()\n",
    "                co1=draw_multi.draw(visim_multi, dataset, person_conf_multi)\n",
    "                plt.imshow(visim_multi)\n",
    "                cv2.imshow('frame', visim_multi)\n",
    "                plt.show()\n",
    "                visualize.waitforbuttonpress()\n",
    "                #print(\"this is draw : \", co1)\n",
    "                if k==0:\n",
    "                    qwr = np.zeros((1920,1080,3), np.uint8)\n",
    "\n",
    "                    cv2.line(qwr, co1[5][0], co1[5][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[7][0], co1[7][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[6][0], co1[6][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[4][0], co1[4][1],(255,0,0),3)\n",
    "\n",
    "                    cv2.line(qwr, co1[9][0], co1[9][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[11][0], co1[11][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[8][0], co1[8][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[10][0], co1[10][1],(255,0,0),3)\n",
    "                    # In[9]:\n",
    "                    # .;cv2.imshow('r',qwr)\n",
    "                    qwr2=\"stick/frame0.jpg\"\n",
    "                    qw1 = cv2.cvtColor(qwr, cv2.COLOR_BGR2GRAY)\n",
    "                    qw2= cv2.cvtColor(qwr2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    fig = plt.figure(\"Images\")\n",
    "                    images = (\"Original\", qw1), (\"Contrast\", qw2)\n",
    "                    for (i, (name, image)) in enumerate(images):\n",
    "                            ax = fig.add_subplot(1, 3, i + 1)\n",
    "                            ax.set_title(name)\n",
    "                    cv2.imshow('frame', image)\n",
    "                    # compare the images\n",
    "                    s,m=compare_images(qw1, qw2, \"Image1 vs Image2\")\n",
    "                    k+=1\n",
    "                    sse=s\n",
    "                    mse=m\n",
    "                if cv2.waitKey(0):\n",
    "                    \n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "plt.close()                \n",
    "elapsed= time.time()-start_time\n",
    "#print(\"sse score : \", sse)\n",
    "print(\"Mean squared error : \", elapsed/100)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "#sys.path.append(os.path.dirname(__file__) + \"/../\")\n",
    "from scipy.misc import imread, imsave\n",
    "from skimage.measure import structural_similarity as ssim\n",
    "from config import load_config\n",
    "from dataset.factory import create as create_dataset\n",
    "from nnet import predict\n",
    "from util import visualize\n",
    "import cv2\n",
    "from dataset.pose_dataset import data_to_input\n",
    "\n",
    "\n",
    "from multiperson.detections import extract_detections\n",
    "from multiperson.predict import SpatialModel, eval_graph, get_person_conf_multicut\n",
    "from multiperson.visualize import PersonDraw, visualize_detections\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tkinter import messagebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vibrate():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_images(slope1, slope2, allowance):\n",
    "    for key in slope1:\n",
    "        if abs(slope1[key]-slope2[key]) > allowance:\n",
    "            vibrate(key)\n",
    "            print(\"error at : \", key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_people:  2\n",
      "#tracked objects: 0\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  3\n",
      "#tracked objects: 1\n",
      "num_people:  3\n",
      "#tracked objects: 3\n",
      "num_people:  5\n",
      "#tracked objects: 3\n",
      "num_people:  5\n",
      "#tracked objects: 5\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "tf.reset_default_graph()\n",
    "cfg = load_config(\"demo/pose_cfg_multi.yaml\")\n",
    "dataset=create_dataset(cfg)\n",
    "sm = SpatialModel(cfg)\n",
    "sm.load()\n",
    "draw_multi = PersonDraw()\n",
    "# Load and setup CNN part detector\n",
    "sess, inputs, outputs = predict.setup_pose_prediction(cfg)\n",
    "fps_time=0\n",
    "# Read image from file\n",
    "dir=os.listdir(\"stick\")\n",
    "k=0\n",
    "cap=cv2.VideoCapture('exer.mp4')\n",
    "i=0\n",
    "while (True):\n",
    "    if i%25 == 0:                   \n",
    "        ret, orig_frame= cap.read()\n",
    "        frame = cv2.resize(orig_frame, (0, 0), fx=0.50, fy=0.50)\n",
    "        #frame=orig_frame\n",
    "        image= frame\n",
    "        image_batch = data_to_input(frame)\n",
    "        # Compute prediction with the CNN\n",
    "        outputs_np = sess.run(outputs, feed_dict={inputs: image_batch})\n",
    "        scmap, locref, pairwise_diff = predict.extract_cnn_output(outputs_np, cfg, dataset.pairwise_stats)\n",
    "        detections = extract_detections(cfg, scmap, locref, pairwise_diff)\n",
    "        unLab, pos_array, unary_array, pwidx_array, pw_array = eval_graph(sm, detections)\n",
    "        m=time.time()\n",
    "        person_conf_multi = get_person_conf_multicut(sm, unLab, unary_array, pos_array)\n",
    "        img = np.copy(image)\n",
    "        #coor = PersonDraw.draw()\n",
    "        visim_multi = img.copy()\n",
    "        co1=draw_multi.draw2(visim_multi, dataset, person_conf_multi, image)\n",
    "        \n",
    "        if len(co1)!=12:\n",
    "            messagebox.showinfo(\"Title\", \"Please adjust camera to show your keypoints\")\n",
    "        cv2.putText(image, \" total error : %f\"%m,(100,20), cv2.FONT_HERSHEY_SIMPLEX,0.75,(255,255,255),2)\n",
    "        cv2.putText(image,\n",
    "                    \"FPS: %f\" % (1.0 / (time.time() - fps_time)),\n",
    "                    (10, 10),  cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                    (0, 255, 0), 2)\n",
    "        cv2.imshow('frame', image)\n",
    "        fps_time=time.time()\n",
    "        #visualize.waitforbuttonpress()\n",
    "        if cv2.waitKey(10)==ord('q'):\n",
    "            break\n",
    "        \"\"\"if k==1:\n",
    "            qwr = np.zeros((1920,1080,3), np.uint8)\n",
    "\n",
    "            cv2.line(qwr, co1[5][0], co1[5][1],(255,0,0),3)\n",
    "            cv2.line(qwr, co1[7][0], co1[7][1],(255,0,0),3)\n",
    "            cv2.line(qwr, co1[6][0], co1[6][1],(255,0,0),3)\n",
    "            cv2.line(qwr, co1[4][0], co1[4][1],(255,0,0),3)\n",
    "\n",
    "            cv2.line(qwr, co1[9][0], co1[9][1],(255,0,0),3)\n",
    "            cv2.line(qwr, co1[11][0], co1[11][1],(255,0,0),3)\n",
    "            cv2.line(qwr, co1[8][0], co1[8][1],(255,0,0),3)\n",
    "            cv2.line(qwr, co1[10][0], co1[10][1],(255,0,0),3)\n",
    "            # In[9]:\n",
    "            cv2.imshow('r',qwr)\n",
    "            qwr2=\"stick/frame\"+str(k)+\".jpg\"\n",
    "            qw1 = cv2.cvtColor(qwr, cv2.COLOR_BGR2GRAY)\n",
    "            qw2= cv2.cvtColor(qwr2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            fig = plt.figure(\"Images\")\n",
    "            images = (\"Original\", qw1), (\"Contrast\", qw2)\n",
    "            for (i, (name, image)) in enumerate(images):\n",
    "                    ax = fig.add_subplot(1, 3, i + 1)\n",
    "                    ax.set_title(name)\n",
    "            plt.imshow(hash(tuple(image)))\n",
    "            # compare the images\n",
    "            s,m=compare_images(qw1, qw2, \"Image1 vs Image2\")\n",
    "\n",
    "            sse=s\n",
    "            mse=m\"\"\"\n",
    "        #print(\"this is draw : \", co1)\n",
    "elapsed= time.time()-start_time\n",
    "#print(\"sse score : \", sse)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(401, 342), (426, 305)],\n",
       " [(401, 342), (349, 310)],\n",
       " [(426, 305), (459, 322)],\n",
       " [(349, 310), (291, 339)]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_people:  1\n",
      "#tracked objects: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time=time.time()\n",
    "tf.reset_default_graph()\n",
    "cfg = load_config(\"demo/pose_cfg_multi.yaml\")\n",
    "dataset = create_dataset(cfg)\n",
    "sm = SpatialModel(cfg)\n",
    "sm.load()\n",
    "draw_multi = PersonDraw()\n",
    "# Load and setup CNN part detector\n",
    "sess, inputs, outputs = predict.setup_pose_prediction(cfg)\n",
    "fps_time=0\n",
    "\n",
    "frame=cv2.imread(\"sample.jpg\")\n",
    "image_batch = data_to_input(frame)\n",
    "image=frame\n",
    "# Compute prediction with the CNN\n",
    "outputs_np = sess.run(outputs, feed_dict={inputs: image_batch})\n",
    "\n",
    "scmap, locref, pairwise_diff = predict.extract_cnn_output(outputs_np, cfg, dataset.pairwise_stats)\n",
    "\n",
    "detections = extract_detections(cfg, scmap, locref, pairwise_diff)\n",
    "\n",
    "unLab, pos_array, unary_array, pwidx_array, pw_array = eval_graph(sm, detections)\n",
    "m=time.time()\n",
    "person_conf_multi = get_person_conf_multicut(sm, unLab, unary_array, pos_array)\n",
    "img = np.copy(frame)\n",
    "#coor = PersonDraw.draw()\n",
    "visim_multi = img.copy()\n",
    "co1=draw_multi.draw2(visim_multi, dataset, person_conf_multi, image)\n",
    "\n",
    "if len(co1)!=12:\n",
    "    messagebox.showinfo(\"Title\", \"Please adjust camera to show your keypoints\")\n",
    "cv2.putText(image, \" total error : %f\"%m,(100,20), cv2.FONT_HERSHEY_SIMPLEX,0.75,(255,255,255),2)\n",
    "cv2.putText(image,\n",
    "            \"FPS: %f\" % (1.0 / (time.time() - fps_time)),\n",
    "            (10, 10),  cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "            (0, 255, 0), 2)\n",
    "cv2.imshow('frame', frame)\n",
    "fps_time=time.time()\n",
    "#visualize.waitforbuttonpress()\n",
    "\"\"\"if k==1:\n",
    "    qwr = np.zeros((1920,1080,3), np.uint8)\n",
    "\n",
    "    cv2.line(qwr, co1[5][0], co1[5][1],(255,0,0),3)\n",
    "    cv2.line(qwr, co1[7][0], co1[7][1],(255,0,0),3)\n",
    "    cv2.line(qwr, co1[6][0], co1[6][1],(255,0,0),3)\n",
    "    cv2.line(qwr, co1[4][0], co1[4][1],(255,0,0),3)\n",
    "\n",
    "    cv2.line(qwr, co1[9][0], co1[9][1],(255,0,0),3)\n",
    "    cv2.line(qwr, co1[11][0], co1[11][1],(255,0,0),3)\n",
    "    cv2.line(qwr, co1[8][0], co1[8][1],(255,0,0),3)\n",
    "    cv2.line(qwr, co1[10][0], co1[10][1],(255,0,0),3)\n",
    "    # In[9]:\n",
    "    cv2.imshow('r',qwr)\n",
    "    qwr2=\"stick/frame\"+str(k)+\".jpg\"\n",
    "    qw1 = cv2.cvtColor(qwr, cv2.COLOR_BGR2GRAY)\n",
    "    qw2= cv2.cvtColor(qwr2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    fig = plt.figure(\"Images\")\n",
    "    images = (\"Original\", qw1), (\"Contrast\", qw2)\n",
    "    for (i, (name, image)) in enumerate(images):\n",
    "            ax = fig.add_subplot(1, 3, i + 1)\n",
    "            ax.set_title(name)\n",
    "    plt.imshow(hash(tuple(image)))\n",
    "    # compare the images\n",
    "    s,m=compare_images(qw1, qw2, \"Image1 vs Image2\")\n",
    "\n",
    "    sse=s\n",
    "    mse=m\"\"\"\n",
    "#print(\"this is draw : \", co1)\n",
    "elapsed= time.time()-start_time\n",
    "#print(\"sse score : \", sse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfig = plt.figure(\"Images\")\\n#images = (\"Original\", qw1), (\"Contrast\", qw2)\\nfor (i, (name, image)) in enumerate(images):\\n    ax = fig.add_subplot(1, 3, i + 1)\\n    ax.set_title(name)\\nplt.imshow(hash(tuple(image)))\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwr = np.zeros((1920,1080,3), np.uint8)\n",
    "\n",
    "cv2.line(qwr, co1[1][0], co1[1][1],(255,0,0),3)\n",
    "cv2.line(qwr, co1[2][0], co1[2][1],(255,0,0),3)\n",
    "cv2.line(qwr, body_dict['backbone'][0],body_dict['backbone'][1] , (255,0,0), 3)\n",
    "cv2.line(qwr, co1[3][0], co1[3][1],(255,0,0),3)\n",
    "cv2.line(qwr, co1[0][0], co1[0][1],(255,0,0),3)\n",
    "\n",
    "cv2.line(qwr, co1[5][0], co1[5][1],(255,0,0),3)\n",
    "cv2.line(qwr, co1[7][0], co1[7][1],(255,0,0),3)\n",
    "cv2.line(qwr, co1[6][0], co1[6][1],(255,0,0),3)\n",
    "cv2.line(qwr, co1[4][0], co1[4][1],(255,0,0),3)\n",
    "\n",
    "cv2.line(qwr, co1[9][0], co1[9][1],(255,0,0),3)\n",
    "cv2.line(qwr, co1[11][0], co1[11][1],(255,0,0),3)\n",
    "cv2.line(qwr, co1[8][0], co1[8][1],(255,0,0),3)\n",
    "cv2.line(qwr, co1[10][0], co1[10][1],(255,0,0),3)\n",
    "# In[9]:\n",
    "plt.imshow(qwr)\n",
    "#qwr2=\"stick/frame\"+str(k)+\".jpg\"\n",
    "#qw1 = cv2.cvtColor(qwr, cv2.COLOR_BGR2GRAY)\n",
    "#qw2= cv2.cvtColor(qwr2, cv2.COLOR_BGR2GRAY)\n",
    "\"\"\"\n",
    "fig = plt.figure(\"Images\")\n",
    "#images = (\"Original\", qw1), (\"Contrast\", qw2)\n",
    "for (i, (name, image)) in enumerate(images):\n",
    "    ax = fig.add_subplot(1, 3, i + 1)\n",
    "    ax.set_title(name)\n",
    "plt.imshow(hash(tuple(image)))\n",
    "\"\"\"\n",
    "# compare the images\n",
    "#s,m=compare_images(qw1, qw2, \"Image1 vs Image2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(258, 63), (267, 55)],\n",
       " [(258, 63), (247, 55)],\n",
       " [(267, 55), (279, 61)],\n",
       " [(247, 55), (235, 61)],\n",
       " [(310, 116), (347, 166)],\n",
       " [(208, 123), (171, 182)],\n",
       " [(347, 166), (346, 240)],\n",
       " [(171, 182), (184, 251)],\n",
       " [(303, 268), (296, 389)],\n",
       " [(234, 269), (245, 392)],\n",
       " [(296, 389), (297, 512)],\n",
       " [(245, 392), (250, 518)]]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('f',frame)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope_calc(co1):\n",
    "    body_dict={'nose_right': co1[0],\n",
    "               'nose_left': co1[1],\n",
    "              'right_eye_ear': co1[2],\n",
    "              'left_eye_ear': co1[3],\n",
    "              'right_upper_arm':co1[4],\n",
    "              'left_upper_arm':co1[5],\n",
    "              'right_forearm': co1[6],\n",
    "              'left_forearm': co1[7],\n",
    "               'right_upper_leg':co1[8],\n",
    "               'left_upper_leg':co1[9],\n",
    "               'right_shin':co1[10],\n",
    "               'left_shin':co1[11]\n",
    "              }\n",
    "    body_dict['backbone']=[(int((body_dict['right_upper_arm'][0][0]+body_dict['left_upper_arm'][0][0])/2),\n",
    "                           int((body_dict['right_upper_arm'][0][1]+body_dict['left_upper_arm'][0][1])/2)),\n",
    "                           (int((body_dict['right_upper_leg'][0][0]+body_dict['left_upper_leg'][0][0])/2),\n",
    "                           int((body_dict['right_upper_leg'][0][1]+body_dict['left_upper_leg'][0][1])/2))]\n",
    "    for key in body_dict:\n",
    "        print(key)\n",
    "        a=math.atan((body_dict['backbone'][1][1]-body_dict['backbone'][0][1])/(body_dict['backbone'][0][0]-body_dict['backbone'][1][0]))\n",
    "        slopes[key]=(math.atan((body_dict[key][1][1]-body_dict[key][0][1])/(body_dict[key][0][0]-body_dict[key][1][0])))-a\n",
    "    print(slopes)\n",
    "    return slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'backbone': 0.0,\n",
       " 'left_eye_ear': 1.9741145502560096,\n",
       " 'left_forearm': 0.12589345487144832,\n",
       " 'left_shin': -0.020667655616565694,\n",
       " 'left_upper_arm': 2.521141883866707,\n",
       " 'left_upper_leg': 0.02886422705204006,\n",
       " 'nose_left': 0.8816706548397705,\n",
       " 'nose_right': 2.237109281936929,\n",
       " 'right_eye_ear': 1.0468193322543973,\n",
       " 'right_forearm': 3.067750577036772,\n",
       " 'right_shin': -0.05219948335974922,\n",
       " 'right_upper_arm': 0.5767409437359904,\n",
       " 'right_upper_leg': 3.0234764372791627}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'backbone': [(259, 119), (268, 268)],\n",
       " 'left_eye_ear': [(247, 55), (235, 61)],\n",
       " 'left_forearm': [(171, 182), (184, 251)],\n",
       " 'left_shin': [(245, 392), (250, 518)],\n",
       " 'left_upper_arm': [(208, 123), (171, 182)],\n",
       " 'left_upper_leg': [(234, 269), (245, 392)],\n",
       " 'nose_left': [(258, 63), (247, 55)],\n",
       " 'nose_right': [(258, 63), (267, 55)],\n",
       " 'right_eye_ear': [(267, 55), (279, 61)],\n",
       " 'right_forearm': [(347, 166), (346, 240)],\n",
       " 'right_shin': [(296, 389), (297, 512)],\n",
       " 'right_upper_arm': [(310, 116), (347, 166)],\n",
       " 'right_upper_leg': [(303, 268), (296, 389)]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
