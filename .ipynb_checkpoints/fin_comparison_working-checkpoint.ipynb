{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import imutils\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "#sys.path.append(os.path.dirname(__file__) + \"/../\")\n",
    "from scipy.misc import imread, imsave\n",
    "from skimage.measure import structural_similarity as ssim\n",
    "from config import load_config\n",
    "from dataset.factory import create as create_dataset\n",
    "from nnet import predict\n",
    "from util import visualize\n",
    "import cv2\n",
    "from dataset.pose_dataset import data_to_input\n",
    "\n",
    "\n",
    "from multiperson.detections import extract_detections\n",
    "from multiperson.predict import SpatialModel, eval_graph, get_person_conf_multicut\n",
    "from multiperson.visualize import PersonDraw, visualize_detections\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tkinter import messagebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vibrate():\n",
    "    pass\n",
    "def compare_images(slope1, slope2, allowance):\n",
    "    for key in slope1:\n",
    "        print(slope1[key]-slope2[key])\n",
    "        if abs(slope1[key]-slope2[key]) > allowance:\n",
    "            vibrate(key)\n",
    "            print(\"error at : \", key)\n",
    "            return (key,slope1[key]-slope2[key])\n",
    "            \n",
    "def slope_calc(co1):\n",
    "    body_dict={'nose_right': co1[0],\n",
    "               'nose_left': co1[1],\n",
    "              'right_eye_ear': co1[2],\n",
    "              'left_eye_ear': co1[3],\n",
    "              'right_upper_arm':co1[4],\n",
    "              'left_upper_arm':co1[5],\n",
    "              'right_forearm': co1[6],\n",
    "              'left_forearm': co1[7],\n",
    "               'right_upper_leg':co1[8],\n",
    "               'left_upper_leg':co1[9],\n",
    "               'right_shin':co1[10],\n",
    "               'left_shin':co1[11]\n",
    "              }\n",
    "    body_dict['backbone']=[(int((body_dict['right_upper_arm'][0][0]+body_dict['left_upper_arm'][0][0])/2),\n",
    "                           int((body_dict['right_upper_arm'][0][1]+body_dict['left_upper_arm'][0][1])/2)),\n",
    "                           (int((body_dict['right_upper_leg'][0][0]+body_dict['left_upper_leg'][0][0])/2),\n",
    "                           int((body_dict['right_upper_leg'][0][1]+body_dict['left_upper_leg'][0][1])/2))]\n",
    "    for key in body_dict:\n",
    "        a=math.atan((body_dict['backbone'][1][1]-body_dict['backbone'][0][1])/(body_dict['backbone'][0][0]-body_dict['backbone'][1][0]))\n",
    "        slopes[key]=(math.atan((body_dict[key][1][1]-body_dict[key][0][1])/(body_dict[key][0][0]-body_dict[key][1][0])))-a\n",
    "    return slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_predict(frame):\n",
    "\n",
    "    # Load and setup CNN part detector\n",
    "    tf.reset_default_graph()\n",
    "    image= frame\n",
    "    image_batch = data_to_input(frame)\n",
    "    \n",
    "    # Compute prediction_n with the CNN\n",
    "    outputs_np = sess.run(outputs, feed_dict={inputs: image_batch})\n",
    "    scmap, locref, pairwise_diff = predict.extract_cnn_output(outputs_np, cfg, dataset.pairwise_stats)\n",
    "    detections = extract_detections(cfg, scmap, locref, pairwise_diff)\n",
    "    unLab, pos_array, unary_array, pwidx_array, pw_array = eval_graph(sm, detections)\n",
    "    m=time.time()\n",
    "    person_conf_multi = get_person_conf_multicut(sm, unLab, unary_array, pos_array)\n",
    "    img = np.copy(image)\n",
    "    #coor = PersonDraw.draw()\n",
    "    visim_multi = img.copy()\n",
    "    co1=draw_multi.draw(visim_multi, dataset, person_conf_multi, image)\n",
    "    return pos_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_people:  2\n",
      "#tracked objects: 0\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  3\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  3\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) /io/opencv/modules/imgproc/src/resize.cpp:4044: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4a2200db2652>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m25\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m#frame=orig_frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0muser_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_frame_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.2) /io/opencv/modules/imgproc/src/resize.cpp:4044: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "cfg = load_config(\"demo/pose_cfg_multi.yaml\")\n",
    "dataset=create_dataset(cfg)\n",
    "sm = SpatialModel(cfg)\n",
    "sm.load()\n",
    "tf.reset_default_graph()\n",
    "draw_multi = PersonDraw()\n",
    "sess, inputs, outputs = predict.setup_pose_prediction(cfg)\n",
    "fps_time=0\n",
    "# Read image from file\n",
    "slopes={}\n",
    "dir=os.listdir(\"stick\")\n",
    "k=0\n",
    "cap=cv2.VideoCapture('exer.mp4')\n",
    "cap_user=cv2.VideoCapture(0)\n",
    "i=0\n",
    "while (True):\n",
    "    ret, orig_frame= cap.read()\n",
    "    ret2, orig_frame_user= cap_user.read()\n",
    "    if i%25 == 0:                   \n",
    "        \n",
    "        frame = cv2.resize(orig_frame, (0, 0), fx=0.50, fy=0.50)\n",
    "        #frame=orig_frame\n",
    "        user_frame=cv2.resize(orig_frame_user, (0, 0), fx=0.50, fy=0.50)\n",
    "        co1=run_predict(frame)\n",
    "        user_co1=run_predict(user_frame)\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            slope_reqd=slope_calc(co1)\n",
    "            slope_user=slope_calc(user_co1)\n",
    "            compare_images(slope_reqd, slope_user)\n",
    "        except IndexError:\n",
    "            #if len(co1)!=len(user_co1):\n",
    "            pass\n",
    "            \n",
    "        cv2.putText(user_frame,\n",
    "                    \"FPS: %f\" % (1.0 / (time.time() - fps_time)),\n",
    "                    (10, 10),  cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                    (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.imshow('user_frame', user_frame)\n",
    "        cv2.imshow('frame', frame)\n",
    "        fps_time=time.time()\n",
    "        #visualize.waitforbuttonpress()\n",
    "        if cv2.waitKey(10)==ord('q'):\n",
    "            break\n",
    "elapsed= time.time()-start_time\n",
    "#print(\"sse score : \", sse)\n",
    "cap.release()\n",
    "cap_user.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cap_user.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST ON IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_people:  1\n",
      "#tracked objects: 0\n",
      "num_people:  1\n",
      "#tracked objects: 1\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "cfg = load_config(\"demo/pose_cfg_multi.yaml\")\n",
    "dataset=create_dataset(cfg)\n",
    "sm = SpatialModel(cfg)\n",
    "sm.load()\n",
    "tf.reset_default_graph()\n",
    "draw_multi = PersonDraw()\n",
    "sess, inputs, outputs = predict.setup_pose_prediction(cfg)\n",
    "fps_time=0\n",
    "# Read image from file\n",
    "slopes={}\n",
    "k=0\n",
    "cap=cv2.VideoCapture('exer.mp4')\n",
    "cap_user=cv2.VideoCapture(0)\n",
    "i=0\n",
    "orig_frame=cv2.imread('sample.jpg')\n",
    "orig_frame_user=orig_frame\n",
    "\n",
    "frame = cv2.resize(orig_frame, (0, 0), fx=0.50, fy=0.50)\n",
    "#frame=orig_frame\n",
    "user_frame=cv2.resize(orig_frame_user, (0, 0), fx=0.50, fy=0.50)\n",
    "co1=run_predict(frame)\n",
    "user_co1=run_predict(user_frame)\n",
    "\n",
    "\n",
    "try:\n",
    "    slope_reqd=slope_calc(co1)\n",
    "    slope_user=slope_calc(user_co1)\n",
    "    compare_images(slope_reqd, slope_user)\n",
    "except IndexError:\n",
    "    #if len(co1)!=len(user_co1):\n",
    "    pass\n",
    "\n",
    "cv2.putText(user_frame,\n",
    "            \"FPS: %f, error : \" % (1.0 / (time.time() - fps_time)),\n",
    "            (10, 10),  cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "            (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow('user_frame', user_frame)\n",
    "cv2.imshow('frame', frame)\n",
    "fps_time=time.time()\n",
    "#visualize.waitforbuttonpress()\n",
    "if cv2.waitKey(0)==ord('q'):\n",
    "    cap.release()\n",
    "    cap_user.release()\n",
    "    cv2.destroyAllWindows()\n",
    "elapsed= time.time()-start_time\n",
    "#print(\"sse score : \", sse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cap_user.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-53fb5ebe8e91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mslope_calc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mco\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-318356b91566>\u001b[0m in \u001b[0;36mslope_calc\u001b[0;34m(co1)\u001b[0m\n\u001b[1;32m     23\u001b[0m                \u001b[0;34m'left_shin'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mco1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m               }\n\u001b[0;32m---> 25\u001b[0;31m     body_dict['backbone']=[(int((body_dict['right_upper_arm'][0][0]+body_dict['left_upper_arm'][0][0])/2),\n\u001b[0m\u001b[1;32m     26\u001b[0m                            int((body_dict['right_upper_arm'][0][1]+body_dict['left_upper_arm'][0][1])/2)),\n\u001b[1;32m     27\u001b[0m                            (int((body_dict['right_upper_leg'][0][0]+body_dict['left_upper_leg'][0][0])/2),\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "slope_calc(co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_people:  1\n",
      "#tracked objects: 1\n"
     ]
    }
   ],
   "source": [
    "frame=cv2.imread('sample.jpg')\n",
    "co=run_predict(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_dict={'nose_right': co1[0],\n",
    "           'nose_left': co1[1],\n",
    "          'right_eye_ear': co1[2],\n",
    "          'left_eye_ear': co1[3],\n",
    "          'right_upper_arm':co1[4],\n",
    "          'left_upper_arm':co1[5],\n",
    "          'right_forearm': co1[6],\n",
    "          'left_forearm': co1[7],\n",
    "           'right_upper_leg':co1[8],\n",
    "           'left_upper_leg':co1[9],\n",
    "           'right_shin':co1[10],\n",
    "           'left_shin':co1[11]\n",
    "          }\n",
    "body_dict['backbone_top']=np.array([int((body_dict['right_upper_arm'][0]+body_dict['left_upper_arm'][0])/2),\n",
    "                       int((body_dict['right_upper_arm'][1]+body_dict['left_upper_arm'][1])/2)])\n",
    "body_dict['backbone_bottom']=np.array([int((body_dict['right_upper_leg'][0]+body_dict['left_upper_leg'][0])/2),\n",
    "                       int((body_dict['right_upper_leg'][1]+body_dict['left_upper_leg'][1])/2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'backbone'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-4056755bb1a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbody_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'backbone'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbody_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'backbone'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'backbone'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbody_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'backbone'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m#slopes[key]=(math.atan((body_dict[key][1][1]-body_dict[key][0][1])/(body_dict[key][0][0]-body_dict[key][1][0])))-a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'backbone'"
     ]
    }
   ],
   "source": [
    "for key in body_dict:\n",
    "    a=math.atan((body_dict['backbone'][1][1]-body_dict['backbone'][0][1])/(body_dict['backbone'][0][0]-body_dict['backbone'][1][0]))\n",
    "    #slopes[key]=(math.atan((body_dict[key][1][1]-body_dict[key][0][1])/(body_dict[key][0][0]-body_dict[key][1][0])))-a\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'backbone_bottom': array([129, 106]),\n",
       " 'backbone_top': array([135,  43]),\n",
       " 'left_eye_ear': array([140.23482698,  29.45351076]),\n",
       " 'left_forearm': array([175.13560033,  84.82418275]),\n",
       " 'left_shin': array([150.00683951, 133.63194036]),\n",
       " 'left_upper_arm': array([154.18243754,  56.84896302]),\n",
       " 'left_upper_leg': array([173.67345417, 122.10704041]),\n",
       " 'nose_left': array([133.01176918,  26.274472  ]),\n",
       " 'nose_right': array([128.8287816 ,  30.89143634]),\n",
       " 'right_eye_ear': array([124.28360933,  25.71700239]),\n",
       " 'right_forearm': array([103.7590704 ,  58.47349012]),\n",
       " 'right_shin': array([ 93.34031546, 128.56551456]),\n",
       " 'right_upper_arm': array([117.19007492,  29.4484024 ]),\n",
       " 'right_upper_leg': array([85.04025865, 90.7046386 ])}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_dict_lines={\n",
    "    'backbone':(body_dict['backbone_top'],body_dict['backbone_bottom'])\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_dict_lines['backbone'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(co1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=np.zeros((1280,1280))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"img\", img)\n",
    "if cv2.waitKey(0):\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
