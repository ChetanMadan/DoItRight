{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "#sys.path.append(os.path.dirname(__file__) + \"/../\")\n",
    "from scipy.misc import imread, imsave\n",
    "from skimage.measure import structural_similarity as ssim\n",
    "from config import load_config\n",
    "from dataset.factory import create as create_dataset\n",
    "from nnet import predict\n",
    "from util import visualize\n",
    "import cv2\n",
    "from dataset.pose_dataset import data_to_input\n",
    "\n",
    "\n",
    "from multiperson.detections import extract_detections\n",
    "from multiperson.predict import SpatialModel, eval_graph, get_person_conf_multicut\n",
    "from multiperson.visualize import PersonDraw, visualize_detections\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "def mse(imageA,imageB):\n",
    "    err = np.sum((imageA.astype(\"float\")-imageB.astype(\"float\"))**2)\n",
    "    err /= float(imageA.shape[0]*imageA.shape[1])\n",
    "    return err\n",
    "\n",
    "def compare_images(imageA, imageB, title):\n",
    "    m = mse(imageA, imageB)\n",
    "    s = ssim(imageA, imageB)\n",
    "    fig = plt.figure(title)\n",
    "    plt.suptitle(\"MSE: %.2f, SSIM: %.2f\" % (m, s))\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    plt.imshow(imageA, cmap = plt.cm.gray)\n",
    "    plt.axis(\"off\")\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    \n",
    "    plt.imshow(imageB, cmap = plt.cm.gray)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    return(s,m)\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "start_time=time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_people:  1\n",
      "#tracked objects: 0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "cfg = load_config(\"demo/pose_cfg_multi.yaml\")\n",
    "dataset = create_dataset(cfg)\n",
    "sm = SpatialModel(cfg)\n",
    "sm.load()\n",
    "draw_multi = PersonDraw()\n",
    "# Load and setup CNN part detector\n",
    "sess, inputs, outputs = predict.setup_pose_prediction(cfg)\n",
    "\n",
    "# Read image from file\n",
    "dir=os.listdir(\"stick\")\n",
    "k=0\n",
    "cap=cv2.VideoCapture(0)\n",
    "i=0\n",
    "while (cap.isOpened()):\n",
    "            i+=1                  \n",
    "            ret, orig_frame= cap.read()\n",
    "            if ret==True:\n",
    "                frame = cv2.resize(orig_frame, (0, 0), fx=0.30, fy=0.30)\n",
    "                image= frame\n",
    "                sse=0\n",
    "                mse=0\n",
    "                image_batch = data_to_input(frame)\n",
    "\n",
    "                # Compute prediction with the CNN\n",
    "                outputs_np = sess.run(outputs, feed_dict={inputs: image_batch})\n",
    "\n",
    "                scmap, locref, pairwise_diff = predict.extract_cnn_output(outputs_np, cfg, dataset.pairwise_stats)\n",
    "\n",
    "                detections = extract_detections(cfg, scmap, locref, pairwise_diff)\n",
    "\n",
    "                unLab, pos_array, unary_array, pwidx_array, pw_array = eval_graph(sm, detections)\n",
    "\n",
    "                person_conf_multi = get_person_conf_multicut(sm, unLab, unary_array, pos_array)\n",
    "                img = np.copy(image)\n",
    "                #coor = PersonDraw.draw()\n",
    "                visim_multi = img.copy()\n",
    "                co1=draw_multi.draw(visim_multi, dataset, person_conf_multi)\n",
    "                plt.imshow(visim_multi)\n",
    "                cv2.imshow('frame', visim_multi)\n",
    "                plt.show()\n",
    "                visualize.waitforbuttonpress()\n",
    "                #print(\"this is draw : \", co1)\n",
    "                if k==0:\n",
    "                    qwr = np.zeros((1920,1080,3), np.uint8)\n",
    "\n",
    "                    cv2.line(qwr, co1[5][0], co1[5][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[7][0], co1[7][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[6][0], co1[6][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[4][0], co1[4][1],(255,0,0),3)\n",
    "\n",
    "                    cv2.line(qwr, co1[9][0], co1[9][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[11][0], co1[11][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[8][0], co1[8][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[10][0], co1[10][1],(255,0,0),3)\n",
    "                    # In[9]:\n",
    "                    # .;cv2.imshow('r',qwr)\n",
    "                    qwr2=\"stick/frame0.jpg\"\n",
    "                    qw1 = cv2.cvtColor(qwr, cv2.COLOR_BGR2GRAY)\n",
    "                    qw2= cv2.cvtColor(qwr2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    fig = plt.figure(\"Images\")\n",
    "                    images = (\"Original\", qw1), (\"Contrast\", qw2)\n",
    "                    for (i, (name, image)) in enumerate(images):\n",
    "                            ax = fig.add_subplot(1, 3, i + 1)\n",
    "                            ax.set_title(name)\n",
    "                    cv2.imshow('frame', image)\n",
    "                    # compare the images\n",
    "                    s,m=compare_images(qw1, qw2, \"Image1 vs Image2\")\n",
    "                    k+=1\n",
    "                    sse=s\n",
    "                    mse=m\n",
    "                if cv2.waitKey(0):\n",
    "                    \n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "plt.close()                \n",
    "elapsed= time.time()-start_time\n",
    "#print(\"sse score : \", sse)\n",
    "print(\"Mean squared error : \", elapsed/100)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
