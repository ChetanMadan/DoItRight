{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "#sys.path.append(os.path.dirname(__file__) + \"/../\")\n",
    "from scipy.misc import imread, imsave\n",
    "from skimage.measure import structural_similarity as ssim\n",
    "from config import load_config\n",
    "from dataset.factory import create as create_dataset\n",
    "from nnet import predict\n",
    "from util import visualize\n",
    "import cv2\n",
    "from dataset.pose_dataset import data_to_input\n",
    "\n",
    "\n",
    "from multiperson.detections import extract_detections\n",
    "from multiperson.predict import SpatialModel, eval_graph, get_person_conf_multicut\n",
    "from multiperson.visualize import PersonDraw, visualize_detections\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "def mse(imageA,imageB):\n",
    "    err = np.sum((imageA.astype(\"float\")-imageB.astype(\"float\"))**2)\n",
    "    err /= float(imageA.shape[0]*imageA.shape[1])\n",
    "    return err\n",
    "\n",
    "def compare_images(imageA, imageB, title):\n",
    "    m = mse(imageA, imageB)\n",
    "    s = ssim(imageA, imageB)\n",
    "    fig = plt.figure(title)\n",
    "    plt.suptitle(\"MSE: %.2f, SSIM: %.2f\" % (m, s))\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    plt.imshow(imageA, cmap = plt.cm.gray)\n",
    "    plt.axis(\"off\")\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    \n",
    "    plt.imshow(imageB, cmap = plt.cm.gray)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    return(s,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_people:  0\n",
      "#tracked objects: 0\n",
      "num_people:  1\n",
      "#tracked objects: 0\n",
      "num_people:  2\n",
      "#tracked objects: 1\n",
      "num_people:  3\n",
      "#tracked objects: 2\n",
      "num_people:  2\n",
      "#tracked objects: 2\n",
      "num_people:  2\n",
      "#tracked objects: 2\n",
      "num_people:  3\n",
      "#tracked objects: 2\n",
      "num_people:  3\n",
      "#tracked objects: 3\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  3\n",
      "#tracked objects: 1\n",
      "num_people:  3\n",
      "#tracked objects: 3\n",
      "num_people:  3\n",
      "#tracked objects: 3\n",
      "num_people:  3\n",
      "#tracked objects: 3\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  3\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  3\n",
      "#tracked objects: 1\n",
      "num_people:  4\n",
      "#tracked objects: 3\n",
      "num_people:  3\n",
      "#tracked objects: 3\n",
      "num_people:  3\n",
      "#tracked objects: 3\n",
      "num_people:  3\n",
      "#tracked objects: 3\n",
      "num_people:  3\n",
      "#tracked objects: 3\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  2\n",
      "#tracked objects: 1\n",
      "num_people:  3\n",
      "#tracked objects: 2\n",
      "num_people:  2\n",
      "#tracked objects: 2\n",
      "num_people:  2\n",
      "#tracked objects: 2\n",
      "num_people:  2\n",
      "#tracked objects: 2\n",
      "num_people:  2\n",
      "#tracked objects: 2\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  2\n",
      "#tracked objects: 1\n",
      "num_people:  2\n",
      "#tracked objects: 2\n",
      "num_people:  2\n",
      "#tracked objects: 2\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  3\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  3\n",
      "#tracked objects: 1\n",
      "num_people:  3\n",
      "#tracked objects: 3\n",
      "num_people:  3\n",
      "#tracked objects: 3\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  2\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  2\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  2\n",
      "#tracked objects: 1\n",
      "num_people:  3\n",
      "#tracked objects: 2\n",
      "num_people:  3\n",
      "#tracked objects: 3\n",
      "num_people:  2\n",
      "#tracked objects: 2\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  2\n",
      "#tracked objects: 1\n",
      "num_people:  2\n",
      "#tracked objects: 2\n",
      "num_people:  3\n",
      "#tracked objects: 2\n",
      "num_people:  2\n",
      "#tracked objects: 2\n",
      "num_people:  2\n",
      "#tracked objects: 2\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  3\n",
      "#tracked objects: 1\n",
      "num_people:  2\n",
      "#tracked objects: 2\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n",
      "num_people:  1\n",
      "#tracked objects: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1c8ba84863b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;31m# Compute prediction with the CNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0moutputs_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mscmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairwise_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_cnn_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "cfg = load_config(\"demo/pose_cfg_multi.yaml\")\n",
    "dataset = create_dataset(cfg)\n",
    "sm = SpatialModel(cfg)\n",
    "sm.load()\n",
    "draw_multi = PersonDraw()\n",
    "# Load and setup CNN part detector\n",
    "sess, inputs, outputs = predict.setup_pose_prediction(cfg)\n",
    "\n",
    "# Read image from file\n",
    "dir=os.listdir(\"stick\")\n",
    "k=0\n",
    "cap=cv2.VideoCapture(0)\n",
    "i=0\n",
    "while True:\n",
    "        if i%20 == 0:                   \n",
    "                ret, orig_frame= cap.read()\n",
    "                frame = cv2.resize(orig_frame, (0, 0), fx=0.30, fy=0.30)\n",
    "                image= frame\n",
    "                sse=0\n",
    "                mse=0\n",
    "                \n",
    "                image_batch = data_to_input(frame)\n",
    "\n",
    "                # Compute prediction with the CNN\n",
    "                outputs_np = sess.run(outputs, feed_dict={inputs: image_batch})\n",
    "\n",
    "                scmap, locref, pairwise_diff = predict.extract_cnn_output(outputs_np, cfg, dataset.pairwise_stats)\n",
    "\n",
    "                detections = extract_detections(cfg, scmap, locref, pairwise_diff)\n",
    "\n",
    "                unLab, pos_array, unary_array, pwidx_array, pw_array = eval_graph(sm, detections)\n",
    "\n",
    "                person_conf_multi = get_person_conf_multicut(sm, unLab, unary_array, pos_array)\n",
    "                img = np.copy(image)\n",
    "                #coor = PersonDraw.draw()\n",
    "                visim_multi = img.copy()\n",
    "                co1=draw_multi.draw(visim_multi, dataset, person_conf_multi)\n",
    "                plt.imshow(visim_multi)\n",
    "                cv2.destroyAllWindows()\n",
    "                #plt.show()\n",
    "                visualize.waitforbuttonpress()\n",
    "                #print(\"this is draw : \", co1)\n",
    "                if k==1:\n",
    "                    qwr = np.zeros((1920,1080,3), np.uint8)\n",
    "\n",
    "                    cv2.line(qwr, co1[5][0], co1[5][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[7][0], co1[7][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[6][0], co1[6][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[4][0], co1[4][1],(255,0,0),3)\n",
    "\n",
    "                    cv2.line(qwr, co1[9][0], co1[9][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[11][0], co1[11][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[8][0], co1[8][1],(255,0,0),3)\n",
    "                    cv2.line(qwr, co1[10][0], co1[10][1],(255,0,0),3)\n",
    "                    # In[9]:\n",
    "                    cv2.imshow('r',qwr)\n",
    "                    qwr2=\"stick/frame\"+str(k)+\".jpg\"\n",
    "                    qw1 = cv2.cvtColor(qwr, cv2.COLOR_BGR2GRAY)\n",
    "                    qw2= cv2.cvtColor(qwr2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    fig = plt.figure(\"Images\")\n",
    "                    images = (\"Original\", qw1), (\"Contrast\", qw2)\n",
    "                    for (i, (name, image)) in enumerate(images):\n",
    "                            ax = fig.add_subplot(1, 3, i + 1)\n",
    "                            ax.set_title(name)\n",
    "                    plt.imshow(hash(tuple(image)))\n",
    "                    # compare the images\n",
    "                    s,m=compare_images(qw1, qw2, \"Image1 vs Image2\")\n",
    "                    k+=1\n",
    "                    sse=s\n",
    "                    mse=m\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    print(\"sse score : \", sse)\n",
    "                    print(\"Mean squared error : \", mse)\n",
    "                    break\n",
    "                \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture('demo/seed.mp4')\n",
    "i=0\n",
    "j=0\n",
    "cap1=cv2.VideoCapture('demo/comp.mp4')\n",
    "while True:\n",
    "    ret, orig_frame= cap.read()\n",
    "    if i%2 == 0:\n",
    "                ret, orig_frame= cap.read()\n",
    "                ret2, frame2 = cap1.read()\n",
    "                frame = cv2.resize(orig_frame, (0, 0), fx=0.35, fy=0.35)\n",
    "                frame2 = cv2.resize(orig_frame, (0, 0), fx=0.35, fy=0.35)\n",
    "                image= frame\n",
    "                cv2.imwrite('written/img%d.jpg'%j, frame)\n",
    "                j=j+1\n",
    "                image2=frame2\n",
    "                if cv2.waitKey(0):\n",
    "                    break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program To Read video \n",
    "# and Extract Frames \n",
    "import cv2 \n",
    "\n",
    "# Function to extract frames \n",
    "def FrameCapture(path): \n",
    "\t\n",
    "\t# Path to video file \n",
    "    vidObj = cv2.VideoCapture(path) \n",
    "\n",
    "\t# Used as counter variable \n",
    "    count = 0\n",
    "    i=0\n",
    "\n",
    "\t# checks whether frames were extracted \n",
    "    success = 1\n",
    "    while success: \n",
    "        if i%30==0:\n",
    "            # vidObj object calls read \n",
    "            # function extract frames \n",
    "            success, image = vidObj.read() \n",
    "\n",
    "            # Saves the frames with frame-count \n",
    "            cv2.imwrite(\"written/frame%d.jpg\" % count, image) \n",
    "\n",
    "            count += 1\n",
    "\n",
    "# Driver Code \n",
    "\t# Calling the function \n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "FrameCapture('demo/seed.mp4') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-a21be215cc0b>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-a21be215cc0b>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    for i in range ()\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#loop for creating stick figures for multiple images :-\n",
    "for i in range ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = os.listdir(\"written\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ded5ba42480f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
