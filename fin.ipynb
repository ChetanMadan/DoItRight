{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "#sys.path.append(os.path.dirname(__file__) + \"/../\")\n",
    "\n",
    "from scipy.misc import imread, imsave\n",
    "from skimage.measure import structural_similarity as ssim\n",
    "from config import load_config\n",
    "from dataset.factory import create as create_dataset\n",
    "from nnet import predict\n",
    "from util import visualize\n",
    "\n",
    "from dataset.pose_dataset import data_to_input\n",
    "\n",
    "from multiperson.detections import extract_detections\n",
    "from multiperson.predict import SpatialModel, eval_graph, get_person_conf_multicut\n",
    "from multiperson.visualize import PersonDraw, visualize_detections\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(imageA,imageB):\n",
    "    err = np.sum((imageA.astype(\"float\")-imageB.astype(\"float\"))**2)\n",
    "    err /= float(imageA.shape[0]*imageA.shape[1])\n",
    "    return err\n",
    "\n",
    "def compare_images(imageA, imageB, title):\n",
    "    m = mse(imageA, imageB)\n",
    "    s = ssim(imageA, imageB)\n",
    "    fig = plt.figure(title)\n",
    "    plt.suptitle(\"MSE: %.2f, SSIM: %.2f\" % (m, s))\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    plt.imshow(imageA, cmap = plt.cm.gray)\n",
    "    plt.axis(\"off\")\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    plt.imshow(imageB, cmap = plt.cm.gray)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    return(s,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_people:  6\n",
      "#tracked objects: 0\n",
      "(238, 174) (238, 168)\n",
      "(238, 174) (233, 178)\n",
      "(238, 168) (244, 166)\n",
      "(233, 178) (231, 191)\n",
      "this is draw :  [[(238, 174), (238, 168)], [(238, 174), (233, 178)], [(238, 168), (244, 166)], [(233, 178), (231, 191)]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-d74aa138ec28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mqwr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1920\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1080\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqwr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mco1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mco1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqwr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mco1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mco1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqwr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mco1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mco1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.reset_default_graph()\n",
    "cfg = load_config(\"demo/pose_cfg_multi.yaml\")\n",
    "\n",
    "dataset = create_dataset(cfg)\n",
    "\n",
    "sm = SpatialModel(cfg)\n",
    "sm.load()\n",
    "\n",
    "draw_multi = PersonDraw()\n",
    "\n",
    "# Load and setup CNN part detector\n",
    "sess, inputs, outputs = predict.setup_pose_prediction(cfg)\n",
    "\n",
    "# Read image from file\n",
    "\n",
    "k=0\n",
    "\n",
    "dir = os.listdir(\"/\")\n",
    "for file in dir:\n",
    "    image=cv2.imread(\"written/\"+file)\n",
    "    image_batch = data_to_input(image)\n",
    "    # Compute prediction with the CNN\n",
    "    detections = extract_detections(cfg, scmap, locref, pairwise_diff)\n",
    "    unLab, pos_array, unary_array, pwidx_array, pw_array = eval_graph(sm, detections)\n",
    "    person_conf_multi = get_person_conf_multicut(sm, unLab, unary_array, pos_array)\n",
    "    img = np.copy(image)\n",
    "    #coor = PersonDraw.draw()\n",
    "    visim_multi = img.copy()\n",
    "\n",
    "    co1=draw_multi.draw(visim_multi, dataset, person_conf_multi)\n",
    "\n",
    "\n",
    "    #plt.show()\n",
    "    visualize.waitforbuttonpress()\n",
    "    print(\"this is draw : \", co1)\n",
    "    qwr = np.zeros((1920,1080,3), np.uint8)\n",
    "\n",
    "    cv2.line(qwr, co1[5][0], co1[5][1],(255,0,0),3)\n",
    "    cv2.line(qwr, co1[7][0], co1[7][1],(255,0,0),3)\n",
    "    cv2.line(qwr, co1[6][0], co1[6][1],(255,0,0),3)\n",
    "    cv2.line(qwr, co1[4][0], co1[4][1],(255,0,0),3)\n",
    "\n",
    "\n",
    "    cv2.line(qwr, co1[9][0], co1[9][1],(255,0,0),3)\n",
    "    cv2.line(qwr, co1[11][0], co1[11][1],(255,0,0),3)\n",
    "    cv2.line(qwr, co1[8][0], co1[8][1],(255,0,0),3)\n",
    "    cv2.line(qwr, co1[10][0], co1[10][1],(255,0,0),3)\n",
    "\n",
    "    cv2.imwrite(\"stick/frame%d.jpg\"%k, qwr)\n",
    "    cv2.destroyAllWindows()\n",
    "    qw1 = cv2.cvtColor(qwr, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(348, 356), (357, 347)],\n",
       " [(348, 356), (336, 349)],\n",
       " [(357, 347), (373, 358)],\n",
       " [(336, 349), (326, 364)],\n",
       " [(400, 423), (422, 490)],\n",
       " [(308, 427), (294, 500)],\n",
       " [(422, 490), (428, 555)],\n",
       " [(294, 500), (301, 565)],\n",
       " [(391, 564), (395, 659)],\n",
       " [(336, 565), (351, 663)],\n",
       " [(395, 659), (398, 762)],\n",
       " [(351, 663), (367, 752)]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwr = np.zeros((1920,1080,3), np.uint8)\n",
    "\n",
    "cv2.line(qwr, co1[5][0], co1[5][1],(255,0,0),3)\n",
    "cv2.line(qwr, co1[7][0], co1[7][1],(255,0,0),3)\n",
    "cv2.line(qwr, co1[6][0], co1[6][1],(255,0,0),3)\n",
    "cv2.line(qwr, co1[4][0], co1[4][1],(255,0,0),3)\n",
    "\n",
    "\n",
    "cv2.line(qwr, co1[9][0], co1[9][1],(255,0,0),3)\n",
    "cv2.line(qwr, co1[11][0], co1[11][1],(255,0,0),3)\n",
    "cv2.line(qwr, co1[8][0], co1[8][1],(255,0,0),3)\n",
    "cv2.line(qwr, co1[10][0], co1[10][1],(255,0,0),3)\n",
    "\n",
    "cv2.imshow('r',qwr)\n",
    "cv2.imshow('r2', qwr2)\n",
    "cv2.destroyAllWindows()\n",
    "qw1 = cv2.cvtColor(qwr, cv2.COLOR_BGR2GRAY)\n",
    "qw2= cv2.cvtColor(qwr2, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dexter/anaconda3/lib/python3.6/site-packages/skimage/measure/_structural_similarity.py:234: skimage_deprecation: Function ``structural_similarity`` is deprecated and will be removed in version 0.14. Use ``compare_ssim`` instead.\n",
      "  def structural_similarity(X, Y, win_size=None, gradient=False,\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(\"Images\")\n",
    "images = (\"Original\", qw1), (\"Contrast\", qw2)\n",
    "for (i, (name, image)) in enumerate(images):\n",
    "    ax = fig.add_subplot(1, 3, i + 1)\n",
    "    ax.set_title(name)\n",
    "    cv2.imshow('fr',image)\n",
    "\n",
    "\n",
    "# compare the images\n",
    "s,m=compare_images(qw1, qw2, \"Image1 vs Image2\")\n",
    "\n",
    "\n",
    "if(s>0.5 and m<=1000):\n",
    "        print(\"The person is present in the database - printing details \")\n",
    "else:\n",
    "        print(\"This person is not on the predefined dataset - employ web scraping script\")\n",
    "        \n",
    "            \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/coco/coco-resnet-101\n",
      "/home/dexter/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_people:  6\n",
      "#tracked objects: 0\n",
      "(238, 174) (238, 168)\n",
      "(238, 174) (233, 178)\n",
      "(238, 168) (244, 166)\n",
      "(233, 178) (231, 191)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "#sys.path.append(os.path.dirname(__file__) + \"/../\")\n",
    "\n",
    "from scipy.misc import imread, imsave\n",
    "\n",
    "from config import load_config\n",
    "from dataset.factory import create as create_dataset\n",
    "from nnet import predict\n",
    "from util import visualize\n",
    "from dataset.pose_dataset import data_to_input\n",
    "\n",
    "from multiperson.detections import extract_detections\n",
    "from multiperson.predict import SpatialModel, eval_graph, get_person_conf_multicut\n",
    "from multiperson.visualize import PersonDraw, visualize_detections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.reset_default_graph()\n",
    "cfg = load_config(\"demo/pose_cfg_multi.yaml\")\n",
    "\n",
    "dataset = create_dataset(cfg)\n",
    "\n",
    "sm = SpatialModel(cfg)\n",
    "sm.load()\n",
    "\n",
    "draw_multi = PersonDraw()\n",
    "\n",
    "# Load and setup CNN part detector\n",
    "sess, inputs, outputs = predict.setup_pose_prediction(cfg)\n",
    "dir=os.listdir(\"written/\")\n",
    "# Read image from file\n",
    "file_name = \"written/frame0.jpg\"\n",
    "image = imread(file_name, mode='RGB')\n",
    "\n",
    "image_batch = data_to_input(image)\n",
    "\n",
    "# Compute prediction with the CNN\n",
    "outputs_np = sess.run(outputs, feed_dict={inputs: image_batch})\n",
    "scmap, locref, pairwise_diff = predict.extract_cnn_output(outputs_np, cfg, dataset.pairwise_stats)\n",
    "\n",
    "detections = extract_detections(cfg, scmap, locref, pairwise_diff)\n",
    "unLab, pos_array, unary_array, pwidx_array, pw_array = eval_graph(sm, detections)\n",
    "person_conf_multi = get_person_conf_multicut(sm, unLab, unary_array, pos_array)\n",
    "\n",
    "img = np.copy(image)\n",
    "#coor = PersonDraw.draw()\n",
    "visim_multi = img.copy()\n",
    "\n",
    "fig = plt.imshow(visim_multi)\n",
    "co1=draw_multi.draw(visim_multi, dataset, person_conf_multi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(238, 174), (238, 168)],\n",
       " [(238, 174), (233, 178)],\n",
       " [(238, 168), (244, 166)],\n",
       " [(233, 178), (231, 191)]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
